{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@BorisAKnyazev/tutorial-on-graph-neural-networks-for-computer-vision-and-beyond-part-1-3d9fada3b80d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from varname import nameof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
    "coord = np.stack((col, row), axis=2).reshape(-1, 2) / img_size\n",
    "\n",
    "dist = cdist(coord, coord)\n",
    "sigma = 0.2*np.pi\n",
    "A = np.exp(-dist**2/sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple fully connected layer for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullyNet, self).__init__()\n",
    "        self.fc = nn.Linear(784, 10, bias=True)\n",
    "    \n",
    "    def forward(self):\n",
    "        return self.fc(x.view(x.size(0), -1))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 10, 28, stride=1, padding=14)\n",
    "        self.fc = nn.Linear(4 * 4 * 10, 10, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = F.max_pool2d(x, 7)\n",
    "        return self.fc(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, img_size=28, pred_edge=False):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.pred_edge = pred_edge\n",
    "        N = img_size**2\n",
    "        self.fc = nn.Linear(N, 10, bias=False)\n",
    "        if pred_edge:\n",
    "            col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
    "            coord = np.stack((col, row), axis=2).reshape(-1, 2)\n",
    "            coord = (coord - np.mean(coord, axis=0)) / (np.std(coord, axis=0) + 1e-5)\n",
    "            coord = torch.from_numpy(coord).float()  # 784,2\n",
    "            coord = torch.cat((coord.unsqueeze(0).repeat(N, 1,  1),\n",
    "                                    coord.unsqueeze(1).repeat(1, N, 1)), dim=2)\n",
    "            #coord = torch.abs(coord[:, :, [0, 1]] - coord[:, :, [2, 3]])\n",
    "            self.pred_edge_fc = nn.Sequential(nn.Linear(4, 64),\n",
    "                                              nn.ReLU(),\n",
    "                                              nn.Linear(64, 1),\n",
    "                                              nn.Tanh())\n",
    "            self.register_buffer('coord', coord)\n",
    "        else:\n",
    "            A = self.precompute_adjacency_images(img_size)\n",
    "            self.register_buffer('A', A)\n",
    "        \n",
    "    @staticmethod\n",
    "    def precompute_adjacency_images(img_size):\n",
    "        col, row = np.meshgrid(np.arange(img_size), np.arange(img_size))\n",
    "        print(\"row shape: \", row.shape)\n",
    "        print(\"col shape: \", col.shape)\n",
    "        \n",
    "        coord = np.stack((col, row), axis=2).reshape(-1, 2) / img_size\n",
    "        print(\"coord shape: \", coord.shape)\n",
    "        \n",
    "        dist = cdist(coord, coord)\n",
    "        print(\"dist shape: \", dist.shape)\n",
    "        \n",
    "        sigma = 0.05*np.pi\n",
    "        # normalize graph\n",
    "        A = np.exp(-dist/sigma**2)\n",
    "        print(\"A shape: \", A.shape)\n",
    "        \n",
    "        A[A < 0.01] = 0\n",
    "        A = torch.from_numpy(A).float()\n",
    "        \n",
    "        D = A.sum(1)\n",
    "        print(\"D shape: \", D.shape)\n",
    "        \n",
    "        D_hat = (D + 1e-5)**(-0.5)\n",
    "        print(\"D_hat shape: \", D_hat.shape)\n",
    "        \n",
    "        A_hat = D_hat.view(-1, 1) * A*D_hat.view(1, -1)\n",
    "        print(\"A_hat shape: \", A_hat.shape)\n",
    "        \n",
    "        A_hat[A_hat > 0.0001] = A_hat[A_hat > 0.0001] - 0.2\n",
    "\n",
    "        print(A_hat[:10, :10])\n",
    "        return A_hat\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B = x.size(0)\n",
    "        if self.pred_edge:\n",
    "            self.A = self.pred_edge_fc(self.coord).squeeze()\n",
    "            \n",
    "        avg_neighbor_features = (torch.bmm(self.A.unsqueeze(0).expand(B, -1, -1),\n",
    "                                 x.view(B, -1, 1)).view(B, -1))\n",
    "        return self.fc(avg_neighbor_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(\n",
    "    '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Training settings\n",
    "    \n",
    "#     parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "#     parser.add_argument('--model', type=str, default='graph', choices=['fc', 'graph', 'conv'],\n",
    "#                         help='model to use for training (default: fc)')\n",
    "#     parser.add_argument('--batch-size', type=int, default=64,\n",
    "#                         help='input batch size for training (default: 64)')\n",
    "#     parser.add_argument('--test-batch-size', type=int, default=1000,\n",
    "#                         help='input batch size for testing (default: 1000)')\n",
    "#     parser.add_argument('--epochs', type=int, default=10,\n",
    "#                         help='number of epochs to train (default: 10)')\n",
    "#     parser.add_argument('--lr', type=float, default=0.001,\n",
    "#                         help='learning rate (default: 0.001)')\n",
    "#     parser.add_argument('--pred_edge', action='store_true', default=False,\n",
    "#                         help='predict edges instead of using predefined ones')\n",
    "#     parser.add_argument('--seed', type=int, default=1,\n",
    "#                         help='random seed (default: 1)')\n",
    "#     parser.add_argument('--log-interval', type=int, default=200,\n",
    "#                         help='how many batches to wait before logging training status')\n",
    "    use_cuda = True\n",
    "    model_mode = 'graph'\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "#     device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=64, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=1000, shuffle=False, **kwargs)\n",
    "\n",
    "    if model_mode == 'fc':\n",
    "        assert not args.pred_edge, \"this flag is meant for graphs\"\n",
    "        model = FullyNet()\n",
    "    elif model_mode == 'graph':\n",
    "        model = GraphNet(pred_edge=True)\n",
    "    else:\n",
    "        model = ConvNet()\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=1e-1 if model_mode == 'conv' else 1e-4)\n",
    "    print('number of trainable parameters: %d' %\n",
    "          np.sum([np.prod(p.size()) if p.requires_grad else 0 for p in model.parameters()]))\n",
    "    log_interval=200\n",
    "    for epoch in range(1, 10 + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphNet(\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=False)\n",
      "  (pred_edge_fc): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      ")\n",
      "number of trainable parameters: 8225\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 12.741712\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 5.777241\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.033909\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.815651\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.745412\n",
      "\n",
      "Test set: Average loss: 0.9349, Accuracy: 7209/10000 (72%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.728821\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.973303\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.399494\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.470690\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.601311\n",
      "\n",
      "Test set: Average loss: 0.5357, Accuracy: 8434/10000 (84%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.575063\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.702684\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.447173\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.537614\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.421787\n",
      "\n",
      "Test set: Average loss: 0.6193, Accuracy: 8264/10000 (83%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.646814\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.351123\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.380601\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.404827\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.594747\n",
      "\n",
      "Test set: Average loss: 0.4077, Accuracy: 8815/10000 (88%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.257771\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.378808\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.436960\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.484458\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.379613\n",
      "\n",
      "Test set: Average loss: 0.3731, Accuracy: 8959/10000 (90%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.336122\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.290814\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.271515\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.327501\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.380118\n",
      "\n",
      "Test set: Average loss: 0.3999, Accuracy: 8826/10000 (88%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.365966\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.393119\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.235105\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.478291\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.573951\n",
      "\n",
      "Test set: Average loss: 0.3670, Accuracy: 8937/10000 (89%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.353422\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.433753\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.254955\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.586641\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.668332\n",
      "\n",
      "Test set: Average loss: 0.3637, Accuracy: 8952/10000 (90%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.393746\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.603355\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.422578\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.242456\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.359116\n",
      "\n",
      "Test set: Average loss: 0.3741, Accuracy: 8932/10000 (89%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.270523\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.326009\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.502084\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.306683\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.406922\n",
      "\n",
      "Test set: Average loss: 0.3466, Accuracy: 9018/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
